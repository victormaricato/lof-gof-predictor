{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 10 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from pandarallel import pandarallel\n",
    "import joblib\n",
    "\n",
    "pandarallel.initialize(progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL\n",
      "NEUTRAL    83924\n",
      "LOF        25376\n",
      "GOF         3137\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VARIANTKEY</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>ENSG</th>\n",
       "      <th>GENE_SYMBOL</th>\n",
       "      <th>AA_POSITION</th>\n",
       "      <th>PROTEIN_REF</th>\n",
       "      <th>PROTEIN_ALT</th>\n",
       "      <th>REF_EMBEDDING_ESM2</th>\n",
       "      <th>ALT_EMBEDDING_ESM2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-100196274-A-C</td>\n",
       "      <td>LOF</td>\n",
       "      <td>ENSG00000137992</td>\n",
       "      <td>DBT</td>\n",
       "      <td>477</td>\n",
       "      <td>MAAVRMLRTWSRNAGKLICVRYFQTCGNVHVLKPNYVCFFGYPSFK...</td>\n",
       "      <td>MAAVRMLRTWSRNAGKLICVRYFQTCGNVHVLKPNYVCFFGYPSFK...</td>\n",
       "      <td>[-0.34903002, -1.0991553, -5.5619345, -0.78340...</td>\n",
       "      <td>[-0.35547394, -1.0680466, -5.513677, -0.804930...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-100196286-T-C</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>ENSG00000137992</td>\n",
       "      <td>DBT</td>\n",
       "      <td>473</td>\n",
       "      <td>MAAVRMLRTWSRNAGKLICVRYFQTCGNVHVLKPNYVCFFGYPSFK...</td>\n",
       "      <td>MAAVRMLRTWSRNAGKLICVRYFQTCGNVHVLKPNYVCFFGYPSFK...</td>\n",
       "      <td>[-0.34903002, -1.0991553, -5.5619345, -0.78340...</td>\n",
       "      <td>[-0.34180462, -1.1007842, -5.556662, -0.767595...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-100196349-T-C</td>\n",
       "      <td>LOF</td>\n",
       "      <td>ENSG00000137992</td>\n",
       "      <td>DBT</td>\n",
       "      <td>452</td>\n",
       "      <td>MAAVRMLRTWSRNAGKLICVRYFQTCGNVHVLKPNYVCFFGYPSFK...</td>\n",
       "      <td>MAAVRMLRTWSRNAGKLICVRYFQTCGNVHVLKPNYVCFFGYPSFK...</td>\n",
       "      <td>[-0.34903002, -1.0991553, -5.5619345, -0.78340...</td>\n",
       "      <td>[-0.37278727, -1.1201291, -5.4481387, -0.74900...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-100206470-G-A</td>\n",
       "      <td>LOF</td>\n",
       "      <td>ENSG00000137992</td>\n",
       "      <td>DBT</td>\n",
       "      <td>395</td>\n",
       "      <td>MAAVRMLRTWSRNAGKLICVRYFQTCGNVHVLKPNYVCFFGYPSFK...</td>\n",
       "      <td>MAAVRMLRTWSRNAGKLICVRYFQTCGNVHVLKPNYVCFFGYPSFK...</td>\n",
       "      <td>[-0.34903002, -1.0991553, -5.5619345, -0.78340...</td>\n",
       "      <td>[-0.3627783, -1.0958921, -5.580294, -0.7817215...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1-100206621-C-T</td>\n",
       "      <td>LOF</td>\n",
       "      <td>ENSG00000137992</td>\n",
       "      <td>DBT</td>\n",
       "      <td>345</td>\n",
       "      <td>MAAVRMLRTWSRNAGKLICVRYFQTCGNVHVLKPNYVCFFGYPSFK...</td>\n",
       "      <td>MAAVRMLRTWSRNAGKLICVRYFQTCGNVHVLKPNYVCFFGYPSFK...</td>\n",
       "      <td>[-0.34903002, -1.0991553, -5.5619345, -0.78340...</td>\n",
       "      <td>[-0.3289509, -1.0981828, -5.574082, -0.8473001...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        VARIANTKEY    LABEL             ENSG GENE_SYMBOL  AA_POSITION  \\\n",
       "0  1-100196274-A-C      LOF  ENSG00000137992         DBT          477   \n",
       "1  1-100196286-T-C  NEUTRAL  ENSG00000137992         DBT          473   \n",
       "2  1-100196349-T-C      LOF  ENSG00000137992         DBT          452   \n",
       "3  1-100206470-G-A      LOF  ENSG00000137992         DBT          395   \n",
       "4  1-100206621-C-T      LOF  ENSG00000137992         DBT          345   \n",
       "\n",
       "                                         PROTEIN_REF  \\\n",
       "0  MAAVRMLRTWSRNAGKLICVRYFQTCGNVHVLKPNYVCFFGYPSFK...   \n",
       "1  MAAVRMLRTWSRNAGKLICVRYFQTCGNVHVLKPNYVCFFGYPSFK...   \n",
       "2  MAAVRMLRTWSRNAGKLICVRYFQTCGNVHVLKPNYVCFFGYPSFK...   \n",
       "3  MAAVRMLRTWSRNAGKLICVRYFQTCGNVHVLKPNYVCFFGYPSFK...   \n",
       "4  MAAVRMLRTWSRNAGKLICVRYFQTCGNVHVLKPNYVCFFGYPSFK...   \n",
       "\n",
       "                                         PROTEIN_ALT  \\\n",
       "0  MAAVRMLRTWSRNAGKLICVRYFQTCGNVHVLKPNYVCFFGYPSFK...   \n",
       "1  MAAVRMLRTWSRNAGKLICVRYFQTCGNVHVLKPNYVCFFGYPSFK...   \n",
       "2  MAAVRMLRTWSRNAGKLICVRYFQTCGNVHVLKPNYVCFFGYPSFK...   \n",
       "3  MAAVRMLRTWSRNAGKLICVRYFQTCGNVHVLKPNYVCFFGYPSFK...   \n",
       "4  MAAVRMLRTWSRNAGKLICVRYFQTCGNVHVLKPNYVCFFGYPSFK...   \n",
       "\n",
       "                                  REF_EMBEDDING_ESM2  \\\n",
       "0  [-0.34903002, -1.0991553, -5.5619345, -0.78340...   \n",
       "1  [-0.34903002, -1.0991553, -5.5619345, -0.78340...   \n",
       "2  [-0.34903002, -1.0991553, -5.5619345, -0.78340...   \n",
       "3  [-0.34903002, -1.0991553, -5.5619345, -0.78340...   \n",
       "4  [-0.34903002, -1.0991553, -5.5619345, -0.78340...   \n",
       "\n",
       "                                  ALT_EMBEDDING_ESM2  \n",
       "0  [-0.35547394, -1.0680466, -5.513677, -0.804930...  \n",
       "1  [-0.34180462, -1.1007842, -5.556662, -0.767595...  \n",
       "2  [-0.37278727, -1.1201291, -5.4481387, -0.74900...  \n",
       "3  [-0.3627783, -1.0958921, -5.580294, -0.7817215...  \n",
       "4  [-0.3289509, -1.0981828, -5.574082, -0.8473001...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(\"../../data/esm2_embeddings.pkl\")\n",
    "print(df.LABEL.value_counts())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "label_mapping = {'NEUTRAL': 0, 'LOF': 1, 'GOF': 2}\n",
    "df['LABEL_MAP'] = df['LABEL'].map(label_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_embedding_df = df['REF_EMBEDDING_ESM2'].apply(pd.Series)\n",
    "ref_embedding_df.columns = ['ref_' + str(col) for col in ref_embedding_df.columns]\n",
    "\n",
    "alt_embedding_df = df['ALT_EMBEDDING_ESM2'].apply(pd.Series)\n",
    "alt_embedding_df.columns = ['alt_' + str(col) for col in alt_embedding_df.columns]\n",
    "\n",
    "X = pd.concat([ref_embedding_df, alt_embedding_df], axis=1)\n",
    "y = df['LABEL_MAP']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 89949 samples\n",
      "Validation set: 11244 samples\n",
      "Testing set: 11244 samples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ref_0</th>\n",
       "      <th>ref_1</th>\n",
       "      <th>ref_2</th>\n",
       "      <th>ref_3</th>\n",
       "      <th>ref_4</th>\n",
       "      <th>ref_5</th>\n",
       "      <th>ref_6</th>\n",
       "      <th>ref_7</th>\n",
       "      <th>ref_8</th>\n",
       "      <th>ref_9</th>\n",
       "      <th>...</th>\n",
       "      <th>alt_1270</th>\n",
       "      <th>alt_1271</th>\n",
       "      <th>alt_1272</th>\n",
       "      <th>alt_1273</th>\n",
       "      <th>alt_1274</th>\n",
       "      <th>alt_1275</th>\n",
       "      <th>alt_1276</th>\n",
       "      <th>alt_1277</th>\n",
       "      <th>alt_1278</th>\n",
       "      <th>alt_1279</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20269</th>\n",
       "      <td>-1.677370</td>\n",
       "      <td>-5.069440</td>\n",
       "      <td>1.790775</td>\n",
       "      <td>2.504909</td>\n",
       "      <td>3.339102</td>\n",
       "      <td>-4.563093</td>\n",
       "      <td>2.255173</td>\n",
       "      <td>7.203899</td>\n",
       "      <td>4.016263</td>\n",
       "      <td>2.939487</td>\n",
       "      <td>...</td>\n",
       "      <td>10.755238</td>\n",
       "      <td>-0.974600</td>\n",
       "      <td>-3.884165</td>\n",
       "      <td>-1.225205</td>\n",
       "      <td>-2.143846</td>\n",
       "      <td>-6.034309</td>\n",
       "      <td>4.386026</td>\n",
       "      <td>-1.678212</td>\n",
       "      <td>3.065606</td>\n",
       "      <td>0.464755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25081</th>\n",
       "      <td>-1.102459</td>\n",
       "      <td>-6.107592</td>\n",
       "      <td>3.221740</td>\n",
       "      <td>1.416400</td>\n",
       "      <td>-2.068759</td>\n",
       "      <td>-4.090089</td>\n",
       "      <td>3.213005</td>\n",
       "      <td>8.528033</td>\n",
       "      <td>1.013075</td>\n",
       "      <td>-1.497316</td>\n",
       "      <td>...</td>\n",
       "      <td>6.419495</td>\n",
       "      <td>2.151514</td>\n",
       "      <td>-2.389071</td>\n",
       "      <td>-6.705357</td>\n",
       "      <td>2.629794</td>\n",
       "      <td>-9.097048</td>\n",
       "      <td>-4.480047</td>\n",
       "      <td>4.491002</td>\n",
       "      <td>2.963162</td>\n",
       "      <td>5.034623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18979</th>\n",
       "      <td>-0.350532</td>\n",
       "      <td>3.262130</td>\n",
       "      <td>-0.268965</td>\n",
       "      <td>-0.764486</td>\n",
       "      <td>3.841102</td>\n",
       "      <td>0.458391</td>\n",
       "      <td>3.354928</td>\n",
       "      <td>-0.144458</td>\n",
       "      <td>-0.380587</td>\n",
       "      <td>1.135145</td>\n",
       "      <td>...</td>\n",
       "      <td>5.466431</td>\n",
       "      <td>0.227993</td>\n",
       "      <td>-1.226452</td>\n",
       "      <td>0.696634</td>\n",
       "      <td>-1.394614</td>\n",
       "      <td>1.112188</td>\n",
       "      <td>0.804384</td>\n",
       "      <td>0.141640</td>\n",
       "      <td>-1.183693</td>\n",
       "      <td>-2.372631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82624</th>\n",
       "      <td>-0.395097</td>\n",
       "      <td>-2.786441</td>\n",
       "      <td>1.088749</td>\n",
       "      <td>-1.369367</td>\n",
       "      <td>-1.041126</td>\n",
       "      <td>2.109502</td>\n",
       "      <td>-0.773584</td>\n",
       "      <td>-5.250056</td>\n",
       "      <td>0.325605</td>\n",
       "      <td>2.864200</td>\n",
       "      <td>...</td>\n",
       "      <td>5.880882</td>\n",
       "      <td>0.483550</td>\n",
       "      <td>-2.217463</td>\n",
       "      <td>-2.529668</td>\n",
       "      <td>2.024062</td>\n",
       "      <td>-2.086164</td>\n",
       "      <td>1.594726</td>\n",
       "      <td>6.007213</td>\n",
       "      <td>5.820427</td>\n",
       "      <td>4.075550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12669</th>\n",
       "      <td>0.325165</td>\n",
       "      <td>-0.978003</td>\n",
       "      <td>0.497170</td>\n",
       "      <td>2.514515</td>\n",
       "      <td>1.613455</td>\n",
       "      <td>-4.068345</td>\n",
       "      <td>-0.003553</td>\n",
       "      <td>8.409565</td>\n",
       "      <td>2.345423</td>\n",
       "      <td>2.246047</td>\n",
       "      <td>...</td>\n",
       "      <td>10.033262</td>\n",
       "      <td>2.935265</td>\n",
       "      <td>-7.642428</td>\n",
       "      <td>-2.454281</td>\n",
       "      <td>-2.555973</td>\n",
       "      <td>-3.343869</td>\n",
       "      <td>5.175861</td>\n",
       "      <td>-0.920529</td>\n",
       "      <td>4.225687</td>\n",
       "      <td>-0.346533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105470</th>\n",
       "      <td>2.164968</td>\n",
       "      <td>-4.266226</td>\n",
       "      <td>0.715478</td>\n",
       "      <td>-0.444632</td>\n",
       "      <td>-0.405317</td>\n",
       "      <td>-2.309124</td>\n",
       "      <td>1.186860</td>\n",
       "      <td>-2.859610</td>\n",
       "      <td>2.714831</td>\n",
       "      <td>4.479666</td>\n",
       "      <td>...</td>\n",
       "      <td>3.218880</td>\n",
       "      <td>-0.116098</td>\n",
       "      <td>-3.977753</td>\n",
       "      <td>0.891991</td>\n",
       "      <td>0.875647</td>\n",
       "      <td>-3.317369</td>\n",
       "      <td>0.002371</td>\n",
       "      <td>-2.504501</td>\n",
       "      <td>-1.602196</td>\n",
       "      <td>-0.823146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86161</th>\n",
       "      <td>1.380002</td>\n",
       "      <td>-5.259967</td>\n",
       "      <td>1.026949</td>\n",
       "      <td>3.624580</td>\n",
       "      <td>1.619648</td>\n",
       "      <td>-2.841283</td>\n",
       "      <td>1.728307</td>\n",
       "      <td>16.387716</td>\n",
       "      <td>4.096630</td>\n",
       "      <td>4.054551</td>\n",
       "      <td>...</td>\n",
       "      <td>10.580894</td>\n",
       "      <td>2.409778</td>\n",
       "      <td>-7.797612</td>\n",
       "      <td>-3.986648</td>\n",
       "      <td>-3.250914</td>\n",
       "      <td>-2.082717</td>\n",
       "      <td>2.017985</td>\n",
       "      <td>-1.519410</td>\n",
       "      <td>3.252011</td>\n",
       "      <td>1.121499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107790</th>\n",
       "      <td>0.115311</td>\n",
       "      <td>2.376308</td>\n",
       "      <td>-0.093431</td>\n",
       "      <td>-1.726331</td>\n",
       "      <td>3.014427</td>\n",
       "      <td>-0.113411</td>\n",
       "      <td>3.079608</td>\n",
       "      <td>0.044947</td>\n",
       "      <td>-0.056119</td>\n",
       "      <td>2.475350</td>\n",
       "      <td>...</td>\n",
       "      <td>5.078647</td>\n",
       "      <td>-1.067601</td>\n",
       "      <td>-3.117823</td>\n",
       "      <td>0.428103</td>\n",
       "      <td>-0.222030</td>\n",
       "      <td>-2.276420</td>\n",
       "      <td>1.770209</td>\n",
       "      <td>-0.676130</td>\n",
       "      <td>-0.221560</td>\n",
       "      <td>1.680834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23934</th>\n",
       "      <td>1.872022</td>\n",
       "      <td>0.940849</td>\n",
       "      <td>0.189312</td>\n",
       "      <td>0.657872</td>\n",
       "      <td>-0.037050</td>\n",
       "      <td>-1.835866</td>\n",
       "      <td>0.723961</td>\n",
       "      <td>-1.615863</td>\n",
       "      <td>-0.450074</td>\n",
       "      <td>3.945919</td>\n",
       "      <td>...</td>\n",
       "      <td>3.365461</td>\n",
       "      <td>3.920008</td>\n",
       "      <td>-3.459285</td>\n",
       "      <td>-1.669742</td>\n",
       "      <td>2.974412</td>\n",
       "      <td>-5.431729</td>\n",
       "      <td>1.983080</td>\n",
       "      <td>-1.477734</td>\n",
       "      <td>-2.642721</td>\n",
       "      <td>2.710844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91282</th>\n",
       "      <td>4.886176</td>\n",
       "      <td>-2.396890</td>\n",
       "      <td>0.166120</td>\n",
       "      <td>-0.708858</td>\n",
       "      <td>-2.869276</td>\n",
       "      <td>1.001111</td>\n",
       "      <td>0.601527</td>\n",
       "      <td>-2.424584</td>\n",
       "      <td>-0.127225</td>\n",
       "      <td>7.171515</td>\n",
       "      <td>...</td>\n",
       "      <td>3.971802</td>\n",
       "      <td>3.918129</td>\n",
       "      <td>-3.393144</td>\n",
       "      <td>-2.246640</td>\n",
       "      <td>-2.130348</td>\n",
       "      <td>-0.273500</td>\n",
       "      <td>-0.419869</td>\n",
       "      <td>4.250569</td>\n",
       "      <td>2.830134</td>\n",
       "      <td>-0.576348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89949 rows × 2560 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ref_0     ref_1     ref_2     ref_3     ref_4     ref_5     ref_6  \\\n",
       "20269  -1.677370 -5.069440  1.790775  2.504909  3.339102 -4.563093  2.255173   \n",
       "25081  -1.102459 -6.107592  3.221740  1.416400 -2.068759 -4.090089  3.213005   \n",
       "18979  -0.350532  3.262130 -0.268965 -0.764486  3.841102  0.458391  3.354928   \n",
       "82624  -0.395097 -2.786441  1.088749 -1.369367 -1.041126  2.109502 -0.773584   \n",
       "12669   0.325165 -0.978003  0.497170  2.514515  1.613455 -4.068345 -0.003553   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "105470  2.164968 -4.266226  0.715478 -0.444632 -0.405317 -2.309124  1.186860   \n",
       "86161   1.380002 -5.259967  1.026949  3.624580  1.619648 -2.841283  1.728307   \n",
       "107790  0.115311  2.376308 -0.093431 -1.726331  3.014427 -0.113411  3.079608   \n",
       "23934   1.872022  0.940849  0.189312  0.657872 -0.037050 -1.835866  0.723961   \n",
       "91282   4.886176 -2.396890  0.166120 -0.708858 -2.869276  1.001111  0.601527   \n",
       "\n",
       "            ref_7     ref_8     ref_9  ...   alt_1270  alt_1271  alt_1272  \\\n",
       "20269    7.203899  4.016263  2.939487  ...  10.755238 -0.974600 -3.884165   \n",
       "25081    8.528033  1.013075 -1.497316  ...   6.419495  2.151514 -2.389071   \n",
       "18979   -0.144458 -0.380587  1.135145  ...   5.466431  0.227993 -1.226452   \n",
       "82624   -5.250056  0.325605  2.864200  ...   5.880882  0.483550 -2.217463   \n",
       "12669    8.409565  2.345423  2.246047  ...  10.033262  2.935265 -7.642428   \n",
       "...           ...       ...       ...  ...        ...       ...       ...   \n",
       "105470  -2.859610  2.714831  4.479666  ...   3.218880 -0.116098 -3.977753   \n",
       "86161   16.387716  4.096630  4.054551  ...  10.580894  2.409778 -7.797612   \n",
       "107790   0.044947 -0.056119  2.475350  ...   5.078647 -1.067601 -3.117823   \n",
       "23934   -1.615863 -0.450074  3.945919  ...   3.365461  3.920008 -3.459285   \n",
       "91282   -2.424584 -0.127225  7.171515  ...   3.971802  3.918129 -3.393144   \n",
       "\n",
       "        alt_1273  alt_1274  alt_1275  alt_1276  alt_1277  alt_1278  alt_1279  \n",
       "20269  -1.225205 -2.143846 -6.034309  4.386026 -1.678212  3.065606  0.464755  \n",
       "25081  -6.705357  2.629794 -9.097048 -4.480047  4.491002  2.963162  5.034623  \n",
       "18979   0.696634 -1.394614  1.112188  0.804384  0.141640 -1.183693 -2.372631  \n",
       "82624  -2.529668  2.024062 -2.086164  1.594726  6.007213  5.820427  4.075550  \n",
       "12669  -2.454281 -2.555973 -3.343869  5.175861 -0.920529  4.225687 -0.346533  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "105470  0.891991  0.875647 -3.317369  0.002371 -2.504501 -1.602196 -0.823146  \n",
       "86161  -3.986648 -3.250914 -2.082717  2.017985 -1.519410  3.252011  1.121499  \n",
       "107790  0.428103 -0.222030 -2.276420  1.770209 -0.676130 -0.221560  1.680834  \n",
       "23934  -1.669742  2.974412 -5.431729  1.983080 -1.477734 -2.642721  2.710844  \n",
       "91282  -2.246640 -2.130348 -0.273500 -0.419869  4.250569  2.830134 -0.576348  \n",
       "\n",
       "[89949 rows x 2560 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_SIZE = 0.1\n",
    "VALIDATION_SIZE = 0.1\n",
    "VALIDATION_RATIO = VALIDATION_SIZE / (1 - TEST_SIZE)\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=VALIDATION_RATIO, random_state=42)\n",
    "\n",
    "print(f\"Training set: {len(X_train)} samples\")\n",
    "print(f\"Validation set: {len(X_val)} samples\")\n",
    "print(f\"Testing set: {len(X_test)} samples\")\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     NEUTRAL       0.85      0.92      0.88      8412\n",
      "         LOF       0.67      0.53      0.59      2543\n",
      "         GOF       0.50      0.22      0.31       289\n",
      "\n",
      "    accuracy                           0.81     11244\n",
      "   macro avg       0.67      0.56      0.59     11244\n",
      "weighted avg       0.80      0.81      0.80     11244\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/victormaricato/mambaforge/envs/lof-gof-prediction/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Train a logistic regression model\n",
    "linear_model = LogisticRegression()\n",
    "linear_model.fit(X_train, y_train)\n",
    "# Evaluate the model\n",
    "lr_pred = linear_model.predict(X_test)\n",
    "print(classification_report(y_test, lr_pred, target_names=label_mapping.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     NEUTRAL       0.91      0.93      0.92      8412\n",
      "         LOF       0.78      0.71      0.74      2543\n",
      "         GOF       0.77      0.67      0.72       289\n",
      "\n",
      "    accuracy                           0.88     11244\n",
      "   macro avg       0.82      0.77      0.79     11244\n",
      "weighted avg       0.87      0.88      0.87     11244\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train a random forest classification model\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train)\n",
    "# Evaluate the model\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "print(classification_report(y_test, rf_pred, target_names=label_mapping.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     NEUTRAL       0.89      0.93      0.91      8412\n",
      "         LOF       0.76      0.67      0.71      2543\n",
      "         GOF       0.77      0.58      0.67       289\n",
      "\n",
      "    accuracy                           0.86     11244\n",
      "   macro avg       0.81      0.73      0.76     11244\n",
      "weighted avg       0.86      0.86      0.86     11244\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train an XGBoost model\n",
    "xgb_model = XGBClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the XGBoost model\n",
    "xgb_pred = xgb_model.predict(X_test)\n",
    "print(classification_report(y_test, xgb_pred, target_names=label_mapping.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.772452 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 652640\n",
      "[LightGBM] [Info] Number of data points in the train set: 89949, number of used features: 2560\n",
      "[LightGBM] [Info] Start training from score -0.291971\n",
      "[LightGBM] [Info] Start training from score -1.491335\n",
      "[LightGBM] [Info] Start training from score -3.570628\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     NEUTRAL       0.89      0.93      0.91      8412\n",
      "         LOF       0.76      0.67      0.71      2543\n",
      "         GOF       0.76      0.63      0.69       289\n",
      "\n",
      "    accuracy                           0.87     11244\n",
      "   macro avg       0.80      0.74      0.77     11244\n",
      "weighted avg       0.86      0.87      0.86     11244\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train a LightGBM model\n",
    "lgb_model = LGBMClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "lgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the LightGBM model\n",
    "lgb_pred = lgb_model.predict(X_test)\n",
    "print(classification_report(y_test, lgb_pred, target_names=label_mapping.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.5186\n",
      "Epoch [20/100], Loss: 0.4966\n",
      "Epoch [30/100], Loss: 0.5283\n",
      "Epoch [40/100], Loss: 0.6108\n",
      "Epoch [50/100], Loss: 0.5332\n",
      "Epoch [60/100], Loss: 0.5734\n",
      "Epoch [70/100], Loss: 0.5515\n",
      "Epoch [80/100], Loss: 0.5508\n",
      "Epoch [90/100], Loss: 0.5422\n",
      "Epoch [100/100], Loss: 0.5635\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     NEUTRAL       0.81      0.89      0.85      8412\n",
      "         LOF       0.49      0.38      0.43      2543\n",
      "         GOF       0.00      0.00      0.00       289\n",
      "\n",
      "    accuracy                           0.75     11244\n",
      "   macro avg       0.43      0.42      0.43     11244\n",
      "weighted avg       0.72      0.75      0.73     11244\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/victormaricato/mambaforge/envs/lof-gof-prediction/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/victormaricato/mambaforge/envs/lof-gof-prediction/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/victormaricato/mambaforge/envs/lof-gof-prediction/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Convert data to PyTorch tensors\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32).to(device)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long).to(device)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long).to(device)\n",
    "\n",
    "# Define the deep learning model\n",
    "class ProteinClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, num_classes, dropout_rate=0.5):\n",
    "        super(ProteinClassifier, self).__init__()\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        self.hidden_layers.append(nn.Linear(input_size, hidden_sizes[0]))\n",
    "        for i in range(1, len(hidden_sizes)):\n",
    "            self.hidden_layers.append(nn.Linear(hidden_sizes[i-1], hidden_sizes[i]))\n",
    "        self.output_layer = nn.Linear(hidden_sizes[-1], num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.hidden_layers:\n",
    "            x = self.relu(layer(x))\n",
    "            x = self.dropout(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "# Set hyperparameters\n",
    "input_size = X_train_tensor.shape[1]\n",
    "hidden_sizes = [256, 128]  # Increased hidden layer sizes\n",
    "num_classes = 3\n",
    "num_epochs = 100  # Increased number of epochs\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.001  # Added weight decay regularization\n",
    "\n",
    "# Initialize the model\n",
    "model = ProteinClassifier(input_size, hidden_sizes, num_classes).to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)  # Changed optimizer to AdamW\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(0, len(X_train_tensor), batch_size):\n",
    "        batch_X = X_train_tensor[i:i+batch_size]\n",
    "        batch_y = y_train_tensor[i:i+batch_size]\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "#  Evaluate the model\n",
    "with torch.no_grad():\n",
    "    dl_outputs = model(X_test_tensor)\n",
    "    _, dl_predicted = torch.max(dl_outputs.data, 1)\n",
    "\n",
    "print(classification_report(y_test_tensor.cpu(), dl_predicted.cpu(), target_names=label_mapping.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with params: {'max_depth': 10, 'min_samples_leaf': 17, 'min_samples_split': 12, 'n_estimators': 437}\n",
      "Getting predictions...                                \n",
      "Training with params: {'max_depth': 20, 'min_samples_leaf': 18, 'min_samples_split': 7, 'n_estimators': 56}\n",
      "Getting predictions...                                                             \n",
      "Training with params: {'max_depth': 12, 'min_samples_leaf': 7, 'min_samples_split': 12, 'n_estimators': 438}\n",
      "Getting predictions...                                                           \n",
      "Training with params: {'max_depth': 19, 'min_samples_leaf': 18, 'min_samples_split': 16, 'n_estimators': 318}\n",
      "Getting predictions...                                                           \n",
      "Training with params: {'max_depth': 22, 'min_samples_leaf': 3, 'min_samples_split': 3, 'n_estimators': 142}\n",
      "Getting predictions...                                                           \n",
      "Training with params: {'max_depth': 13, 'min_samples_leaf': 8, 'min_samples_split': 15, 'n_estimators': 286}\n",
      "Getting predictions...                                                           \n",
      "Training with params: {'max_depth': 84, 'min_samples_leaf': 7, 'min_samples_split': 2, 'n_estimators': 409}\n",
      "Getting predictions...                                                           \n",
      "Training with params: {'max_depth': 23, 'min_samples_leaf': 16, 'min_samples_split': 13, 'n_estimators': 452}\n",
      "Getting predictions...                                                             \n",
      "Training with params: {'max_depth': 53, 'min_samples_leaf': 19, 'min_samples_split': 4, 'n_estimators': 270}\n",
      "Getting predictions...                                                              \n",
      "Training with params: {'max_depth': 48, 'min_samples_leaf': 12, 'min_samples_split': 17, 'n_estimators': 498}\n",
      "Getting predictions...                                                              \n",
      "Training with params: {'max_depth': 8, 'min_samples_leaf': 8, 'min_samples_split': 18, 'n_estimators': 146}\n",
      "Getting predictions...                                                               \n",
      "Training with params: {'max_depth': 37, 'min_samples_leaf': 14, 'min_samples_split': 10, 'n_estimators': 185}\n",
      "Getting predictions...                                                              \n",
      "Training with params: {'max_depth': 11, 'min_samples_leaf': 10, 'min_samples_split': 17, 'n_estimators': 119}\n",
      "Getting predictions...                                                            \n",
      "Training with params: {'max_depth': 19, 'min_samples_leaf': 8, 'min_samples_split': 17, 'n_estimators': 461}\n",
      "Getting predictions...                                                            \n",
      "Training with params: {'max_depth': 84, 'min_samples_leaf': 7, 'min_samples_split': 9, 'n_estimators': 264}\n",
      "Getting predictions...                                                            \n",
      "Training with params: {'max_depth': 10, 'min_samples_leaf': 3, 'min_samples_split': 7, 'n_estimators': 379}\n",
      "Getting predictions...                                                            \n",
      "Training with params: {'max_depth': 89, 'min_samples_leaf': 6, 'min_samples_split': 10, 'n_estimators': 292}\n",
      "Getting predictions...                                                            \n",
      "Training with params: {'max_depth': 31, 'min_samples_leaf': 18, 'min_samples_split': 4, 'n_estimators': 125}\n",
      "Getting predictions...                                                            \n",
      "Training with params: {'max_depth': 88, 'min_samples_leaf': 3, 'min_samples_split': 6, 'n_estimators': 153}\n",
      "Getting predictions...                                                            \n",
      "Training with params: {'max_depth': 37, 'min_samples_leaf': 13, 'min_samples_split': 3, 'n_estimators': 145}\n",
      "Getting predictions...                                                            \n",
      "Training with params: {'max_depth': 96, 'min_samples_leaf': 5, 'min_samples_split': 7, 'n_estimators': 202}\n",
      "Getting predictions...                                                            \n",
      "Training with params: {'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 6, 'n_estimators': 209}\n",
      "Getting predictions...                                                            \n",
      "Training with params: {'max_depth': 71, 'min_samples_leaf': 2, 'min_samples_split': 6, 'n_estimators': 58}\n",
      "Getting predictions...                                                            \n",
      "Training with params: {'max_depth': 69, 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 52}\n",
      "Getting predictions...                                                            \n",
      "Training with params: {'max_depth': 71, 'min_samples_leaf': 2, 'min_samples_split': 8, 'n_estimators': 86}\n",
      "Getting predictions...                                                            \n",
      "Training with params: {'max_depth': 71, 'min_samples_leaf': 10, 'min_samples_split': 5, 'n_estimators': 235}\n",
      "Getting predictions...                                                            \n",
      "Training with params: {'max_depth': 62, 'min_samples_leaf': 2, 'min_samples_split': 9, 'n_estimators': 347}\n",
      "Getting predictions...                                                            \n",
      "Training with params: {'max_depth': 99, 'min_samples_leaf': 4, 'min_samples_split': 9, 'n_estimators': 351}\n",
      "Getting predictions...                                                            \n",
      "Training with params: {'max_depth': 54, 'min_samples_leaf': 5, 'min_samples_split': 13, 'n_estimators': 337}\n",
      "Getting predictions...                                                             \n",
      "Training with params: {'max_depth': 63, 'min_samples_leaf': 10, 'min_samples_split': 11, 'n_estimators': 233}\n",
      "Getting predictions...                                                             \n",
      "Training with params: {'max_depth': 62, 'min_samples_leaf': 2, 'min_samples_split': 14, 'n_estimators': 407}\n",
      "Getting predictions...                                                             \n",
      "Training with params: {'max_depth': 79, 'min_samples_leaf': 15, 'min_samples_split': 11, 'n_estimators': 191}\n",
      "Getting predictions...                                                             \n",
      "Training with params: {'max_depth': 94, 'min_samples_leaf': 4, 'min_samples_split': 8, 'n_estimators': 234}\n",
      "Getting predictions...                                                             \n",
      "Training with params: {'max_depth': 45, 'min_samples_leaf': 4, 'min_samples_split': 20, 'n_estimators': 324}\n",
      "Getting predictions...                                                             \n",
      "Training with params: {'max_depth': 77, 'min_samples_leaf': 6, 'min_samples_split': 12, 'n_estimators': 356}\n",
      "Getting predictions...                                                             \n",
      "Training with params: {'max_depth': 61, 'min_samples_leaf': 11, 'min_samples_split': 2, 'n_estimators': 298}\n",
      "Getting predictions...                                                             \n",
      "Training with params: {'max_depth': 29, 'min_samples_leaf': 9, 'min_samples_split': 8, 'n_estimators': 385}\n",
      "Getting predictions...                                                             \n",
      "Training with params: {'max_depth': 44, 'min_samples_leaf': 3, 'min_samples_split': 6, 'n_estimators': 251}\n",
      "Getting predictions...                                                             \n",
      "Training with params: {'max_depth': 58, 'min_samples_leaf': 6, 'min_samples_split': 10, 'n_estimators': 478}\n",
      "Getting predictions...                                                             \n",
      "Training with params: {'max_depth': 78, 'min_samples_leaf': 17, 'min_samples_split': 3, 'n_estimators': 312}\n",
      "Getting predictions...                                                               \n",
      "Training with params: {'max_depth': 66, 'min_samples_leaf': 20, 'min_samples_split': 13, 'n_estimators': 206}\n",
      "Getting predictions...                                                               \n",
      "Training with params: {'max_depth': 100, 'min_samples_leaf': 12, 'min_samples_split': 15, 'n_estimators': 425}\n",
      "Getting predictions...                                                               \n",
      "Training with params: {'max_depth': 38, 'min_samples_leaf': 7, 'min_samples_split': 9, 'n_estimators': 164}\n",
      "Getting predictions...                                                               \n",
      "Training with params: {'max_depth': 92, 'min_samples_leaf': 9, 'min_samples_split': 5, 'n_estimators': 83}\n",
      "Getting predictions...                                                               \n",
      "Training with params: {'max_depth': 83, 'min_samples_leaf': 2, 'min_samples_split': 12, 'n_estimators': 383}\n",
      "Getting predictions...                                                              \n",
      "Training with params: {'max_depth': 17, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 273}\n",
      "Getting predictions...                                                               \n",
      "Training with params: {'max_depth': 49, 'min_samples_leaf': 14, 'min_samples_split': 7, 'n_estimators': 173}\n",
      "Getting predictions...                                                               \n",
      "Training with params: {'max_depth': 57, 'min_samples_leaf': 7, 'min_samples_split': 20, 'n_estimators': 115}\n",
      "Getting predictions...                                                              \n",
      "Training with params: {'max_depth': 28, 'min_samples_leaf': 3, 'min_samples_split': 14, 'n_estimators': 499}\n",
      "Getting predictions...                                                              \n",
      "Training with params: {'max_depth': 74, 'min_samples_leaf': 9, 'min_samples_split': 10, 'n_estimators': 218}\n",
      "Getting predictions...                                                               \n",
      "100%|██████████| 50/50 [1:21:03<00:00, 97.27s/trial, best loss: -0.7927639733221822] \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     NEUTRAL       0.91      0.93      0.92      8412\n",
      "         LOF       0.78      0.72      0.75      2543\n",
      "         GOF       0.78      0.66      0.71       289\n",
      "\n",
      "    accuracy                           0.88     11244\n",
      "   macro avg       0.82      0.77      0.79     11244\n",
      "weighted avg       0.87      0.88      0.88     11244\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../../data/best_esm1_model.pkl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def objective(params):\n",
    "    model = RandomForestClassifier(**params, random_state=42, n_jobs=-1)\n",
    "    print(f\"Training with params: {params}\")\n",
    "    model = model.fit(X_train, y_train)\n",
    "    print(f\"Getting predictions...\")\n",
    "    y_pred = model.predict(X_test)\n",
    "    score = f1_score(y_test, y_pred, average='macro')\n",
    "    return {'loss': -score,'status': STATUS_OK}\n",
    "\n",
    "# Define the hyperparameter search space\n",
    "space = {\n",
    "    'max_depth': hp.uniformint('max_depth', 5, 100),\n",
    "    'n_estimators': hp.uniformint('n_estimators', 50, 500),\n",
    "    'min_samples_leaf': hp.uniformint('min_samples_leaf', 2, 20),\n",
    "    'min_samples_split': hp.uniformint('min_samples_split', 2,20),\n",
    "}\n",
    "\n",
    "# Perform Bayesian optimization\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=50, trials=trials)\n",
    "\n",
    "best_params = {\n",
    "  \"min_samples_leaf\": int(best['min_samples_leaf']),\n",
    "  \"min_samples_split\": int(best['min_samples_split']),\n",
    "  \"max_depth\": int(best['max_depth']),\n",
    "  \"n_estimators\": int(best['n_estimators']),\n",
    "}\n",
    "\n",
    "best_model = RandomForestClassifier(**best_params, random_state=42)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the tuned model\n",
    "best_model_pred = best_model.predict(X_test)\n",
    "print(classification_report(y_test, best_model_pred, target_names=label_mapping.keys()))\n",
    "joblib.dump(best_model, '../../data/best_esm2_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../data/best_esm2_model.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(best_model, '../../data/best_esm2_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"PREDICTION\"] = best_model.predict(X)\n",
    "df[\"PREDICTED_LABEL\"] = df[\"PREDICTION\"].map({v: k for k, v in label_mapping.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcb5222c560347c38c6fa4652a3d0361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=11244), Label(value='0 / 11244')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Relationship between cosine similarity and label\n",
    "def cosine_similarity_score(row):\n",
    "    return cosine_similarity([row[\"REF_EMBEDDING_ESM2\"]], [row[\"ALT_EMBEDDING_ESM2\"]])[0][0]\n",
    "\n",
    "df['COSINE_SIMILARITY'] = df.parallel_apply(cosine_similarity_score, axis=1)\n",
    "df['COSINE_DISTANCE'] = 1 - df['COSINE_SIMILARITY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VARIANTKEY</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>ENSG</th>\n",
       "      <th>GENE_SYMBOL</th>\n",
       "      <th>AA_POSITION</th>\n",
       "      <th>PROTEIN_REF</th>\n",
       "      <th>PROTEIN_ALT</th>\n",
       "      <th>REF_EMBEDDING_ESM2</th>\n",
       "      <th>ALT_EMBEDDING_ESM2</th>\n",
       "      <th>LABEL_MAP</th>\n",
       "      <th>PREDICTION</th>\n",
       "      <th>PREDICTED_LABEL</th>\n",
       "      <th>COSINE_SIMILARITY</th>\n",
       "      <th>COSINE_DISTANCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-100196274-A-C</td>\n",
       "      <td>LOF</td>\n",
       "      <td>ENSG00000137992</td>\n",
       "      <td>DBT</td>\n",
       "      <td>477</td>\n",
       "      <td>MAAVRMLRTWSRNAGKLICVRYFQTCGNVHVLKPNYVCFFGYPSFK...</td>\n",
       "      <td>MAAVRMLRTWSRNAGKLICVRYFQTCGNVHVLKPNYVCFFGYPSFK...</td>\n",
       "      <td>[-0.34903002, -1.0991553, -5.5619345, -0.78340...</td>\n",
       "      <td>[-0.35547394, -1.0680466, -5.513677, -0.804930...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>LOF</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-100196286-T-C</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>ENSG00000137992</td>\n",
       "      <td>DBT</td>\n",
       "      <td>473</td>\n",
       "      <td>MAAVRMLRTWSRNAGKLICVRYFQTCGNVHVLKPNYVCFFGYPSFK...</td>\n",
       "      <td>MAAVRMLRTWSRNAGKLICVRYFQTCGNVHVLKPNYVCFFGYPSFK...</td>\n",
       "      <td>[-0.34903002, -1.0991553, -5.5619345, -0.78340...</td>\n",
       "      <td>[-0.34180462, -1.1007842, -5.556662, -0.767595...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-100196349-T-C</td>\n",
       "      <td>LOF</td>\n",
       "      <td>ENSG00000137992</td>\n",
       "      <td>DBT</td>\n",
       "      <td>452</td>\n",
       "      <td>MAAVRMLRTWSRNAGKLICVRYFQTCGNVHVLKPNYVCFFGYPSFK...</td>\n",
       "      <td>MAAVRMLRTWSRNAGKLICVRYFQTCGNVHVLKPNYVCFFGYPSFK...</td>\n",
       "      <td>[-0.34903002, -1.0991553, -5.5619345, -0.78340...</td>\n",
       "      <td>[-0.37278727, -1.1201291, -5.4481387, -0.74900...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>LOF</td>\n",
       "      <td>0.999976</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-100206470-G-A</td>\n",
       "      <td>LOF</td>\n",
       "      <td>ENSG00000137992</td>\n",
       "      <td>DBT</td>\n",
       "      <td>395</td>\n",
       "      <td>MAAVRMLRTWSRNAGKLICVRYFQTCGNVHVLKPNYVCFFGYPSFK...</td>\n",
       "      <td>MAAVRMLRTWSRNAGKLICVRYFQTCGNVHVLKPNYVCFFGYPSFK...</td>\n",
       "      <td>[-0.34903002, -1.0991553, -5.5619345, -0.78340...</td>\n",
       "      <td>[-0.3627783, -1.0958921, -5.580294, -0.7817215...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>LOF</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1-100206621-C-T</td>\n",
       "      <td>LOF</td>\n",
       "      <td>ENSG00000137992</td>\n",
       "      <td>DBT</td>\n",
       "      <td>345</td>\n",
       "      <td>MAAVRMLRTWSRNAGKLICVRYFQTCGNVHVLKPNYVCFFGYPSFK...</td>\n",
       "      <td>MAAVRMLRTWSRNAGKLICVRYFQTCGNVHVLKPNYVCFFGYPSFK...</td>\n",
       "      <td>[-0.34903002, -1.0991553, -5.5619345, -0.78340...</td>\n",
       "      <td>[-0.3289509, -1.0981828, -5.574082, -0.8473001...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>LOF</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        VARIANTKEY    LABEL             ENSG GENE_SYMBOL  AA_POSITION  \\\n",
       "0  1-100196274-A-C      LOF  ENSG00000137992         DBT          477   \n",
       "1  1-100196286-T-C  NEUTRAL  ENSG00000137992         DBT          473   \n",
       "2  1-100196349-T-C      LOF  ENSG00000137992         DBT          452   \n",
       "3  1-100206470-G-A      LOF  ENSG00000137992         DBT          395   \n",
       "4  1-100206621-C-T      LOF  ENSG00000137992         DBT          345   \n",
       "\n",
       "                                         PROTEIN_REF  \\\n",
       "0  MAAVRMLRTWSRNAGKLICVRYFQTCGNVHVLKPNYVCFFGYPSFK...   \n",
       "1  MAAVRMLRTWSRNAGKLICVRYFQTCGNVHVLKPNYVCFFGYPSFK...   \n",
       "2  MAAVRMLRTWSRNAGKLICVRYFQTCGNVHVLKPNYVCFFGYPSFK...   \n",
       "3  MAAVRMLRTWSRNAGKLICVRYFQTCGNVHVLKPNYVCFFGYPSFK...   \n",
       "4  MAAVRMLRTWSRNAGKLICVRYFQTCGNVHVLKPNYVCFFGYPSFK...   \n",
       "\n",
       "                                         PROTEIN_ALT  \\\n",
       "0  MAAVRMLRTWSRNAGKLICVRYFQTCGNVHVLKPNYVCFFGYPSFK...   \n",
       "1  MAAVRMLRTWSRNAGKLICVRYFQTCGNVHVLKPNYVCFFGYPSFK...   \n",
       "2  MAAVRMLRTWSRNAGKLICVRYFQTCGNVHVLKPNYVCFFGYPSFK...   \n",
       "3  MAAVRMLRTWSRNAGKLICVRYFQTCGNVHVLKPNYVCFFGYPSFK...   \n",
       "4  MAAVRMLRTWSRNAGKLICVRYFQTCGNVHVLKPNYVCFFGYPSFK...   \n",
       "\n",
       "                                  REF_EMBEDDING_ESM2  \\\n",
       "0  [-0.34903002, -1.0991553, -5.5619345, -0.78340...   \n",
       "1  [-0.34903002, -1.0991553, -5.5619345, -0.78340...   \n",
       "2  [-0.34903002, -1.0991553, -5.5619345, -0.78340...   \n",
       "3  [-0.34903002, -1.0991553, -5.5619345, -0.78340...   \n",
       "4  [-0.34903002, -1.0991553, -5.5619345, -0.78340...   \n",
       "\n",
       "                                  ALT_EMBEDDING_ESM2  LABEL_MAP  PREDICTION  \\\n",
       "0  [-0.35547394, -1.0680466, -5.513677, -0.804930...          1           1   \n",
       "1  [-0.34180462, -1.1007842, -5.556662, -0.767595...          0           0   \n",
       "2  [-0.37278727, -1.1201291, -5.4481387, -0.74900...          1           1   \n",
       "3  [-0.3627783, -1.0958921, -5.580294, -0.7817215...          1           1   \n",
       "4  [-0.3289509, -1.0981828, -5.574082, -0.8473001...          1           1   \n",
       "\n",
       "  PREDICTED_LABEL  COSINE_SIMILARITY  COSINE_DISTANCE  \n",
       "0             LOF           0.999994         0.000006  \n",
       "1         NEUTRAL           0.999997         0.000003  \n",
       "2             LOF           0.999976         0.000024  \n",
       "3             LOF           0.999997         0.000003  \n",
       "4             LOF           0.999992         0.000008  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = X_train.copy()\n",
    "train[\"label\"] = y_train\n",
    "train[\"PREDICTION\"] = best_model.predict(X_train)\n",
    "train[\"PREDICTED_LABEL\"] = train[\"PREDICTION\"].map({v: k for k, v in label_mapping.items()})\n",
    "\n",
    "test = X_test.copy()\n",
    "test[\"label\"] = y_test\n",
    "test[\"PREDICTION\"] = best_model.predict(X_test)\n",
    "test[\"PREDICTED_LABEL\"] = test[\"PREDICTION\"].map({v: k for k, v in label_mapping.items()})\n",
    "\n",
    "validation = X_val.copy()\n",
    "validation[\"label\"] = y_val\n",
    "validation[\"PREDICTION\"] = best_model.predict(X_val)\n",
    "validation[\"PREDICTED_LABEL\"] = validation[\"PREDICTION\"].map({v: k for k, v in label_mapping.items()})\n",
    "\n",
    "train.to_pickle(\"../../data/esm2_embeddings_train.pkl\")\n",
    "test.to_pickle(\"../../data/esm2_embeddings_test.pkl\")\n",
    "validation.to_pickle(\"../../data/esm2_embeddings_validation.pkl\")\n",
    "\n",
    "df.to_pickle(\"../../data/esm2_embeddings_with_predictions.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
